# MentaLLM_Chinese

Titre: TinyMentaLLM: Small but Powerful Chinese Large Language Models for Depression Detection in Social Media Texts

Abstract: Depression is a major risk factor for suicide globally, and mental health concerns are increasingly prominent. Social media serves as a key platform for expressing emotions, with users sharing various aspects of their lives, including emotional experiences. Numerous studies have shown that NLP techniques are effective in detecting depressive states. However, existing classification-based methods provide only labels, without offering comprehensible explanatory analysis. Although generative large language models (LLMs) can provide some textual explanations during label generation, deploying high-performing, large-scale LLMs raises concerns about infrastructure, privacy, and data security. Furthermore, smaller LLMs that are easier to deploy often suffer from inaccuracies and generate text with many hallucinations. To address these issues, we utilize a textometry method to construct a small yet representative dataset. With this dataset, we employ an efficient fine-tuning strategy to enhance the accuracy of depression detection in two lightweight generative models (0.5B and 1.5B parameters). These two Tiny Mental LLMs (TMLs) show performance comparable to much larger and higher-performing models.
